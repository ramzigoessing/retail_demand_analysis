{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOYocijIKaDgRXHrHLCOnvP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ramzigoessing/retail_demand_analysis/blob/main/data_prep.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# import_libraries"
      ],
      "metadata": {
        "id": "_f2fXdZcS9Gq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import requests\n",
        "import io"
      ],
      "metadata": {
        "id": "tZAIp4S95hdz"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# download_of_data"
      ],
      "metadata": {
        "id": "JGSeUaTDAEeR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we generate direct download links for our data stored on google drive and load each csv file into a pandas dataframe with descriptive variable names."
      ],
      "metadata": {
        "id": "NDrjfZaMAIUH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "w8GJkSznBE1r"
      },
      "outputs": [],
      "source": [
        "def make_drive_url(file_id):\n",
        "    return f\"https://drive.google.com/uc?id={file_id}\"\n",
        "\n",
        "def load_csv_from_url(url):\n",
        "    response = requests.get(url)\n",
        "    response.raise_for_status()\n",
        "    return pd.read_csv(io.StringIO(response.text))\n",
        "\n",
        "file_ids = {\n",
        "    \"holiday_events\": \"1RMjSuqHXHTwAw_PGD5XVjhA3agaAGHDH\",\n",
        "    \"items\": \"1ogMRixVhNY6XOJtIRtkRllyOyzw1nqya\",\n",
        "    \"oil\": \"1Q59vk2v4WQ-Rpc9t2nqHcsZM3QWGFje_\",\n",
        "    \"stores\": \"1Ei0MUXmNhmOcmrlPad8oklnFEDM95cDi\",\n",
        "    \"train\": \"1oEX8NEJPY7wPmSJ0n7lO1JUFYyZjFBRv\",\n",
        "    \"transactions\": \"1PW5LnAEAiL43fI5CRDn_h6pgDG5rtBW_\"\n",
        "}\n",
        "\n",
        "df_holiday_events = load_csv_from_url(make_drive_url(file_ids[\"holiday_events\"]))\n",
        "df_items          = load_csv_from_url(make_drive_url(file_ids[\"items\"]))\n",
        "df_oil            = load_csv_from_url(make_drive_url(file_ids[\"oil\"]))\n",
        "df_stores         = load_csv_from_url(make_drive_url(file_ids[\"stores\"]))\n",
        "df_transactions   = load_csv_from_url(make_drive_url(file_ids[\"transactions\"]))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# download_of_df_train"
      ],
      "metadata": {
        "id": "rZaeLCVnLXc6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since `df_train` is our largest dataset, we have to treat it differently due to the limited memory in Google Colab. We use `gdown` to download the file directly from Google Drive and then load it in chunks, filtering only the stores located in the state of *Guayas*. Finally, we combine the filtered chunks and draw a random sample of 300,000 rows to create a manageable `df_train` DataFrame for further analysis.\n"
      ],
      "metadata": {
        "id": "evGw9-Z0LXRa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U gdown\n",
        "import gdown\n",
        "\n",
        "train_url = make_drive_url(file_ids[\"train\"])\n",
        "\n",
        "gdown.download(train_url, \"train.csv\", quiet=False)\n",
        "\n",
        "store_ids = df_stores[df_stores['state'] == 'Guayas']['store_nbr'].unique()\n",
        "\n",
        "\n",
        "chunk_size = 10**6\n",
        "filtered_chunks = []\n",
        "\n",
        "for chunk in pd.read_csv(\"train.csv\", chunksize=chunk_size):\n",
        "    chunk_filtered = chunk[chunk['store_nbr'].isin(store_ids)]\n",
        "    filtered_chunks.append(chunk_filtered)\n",
        "    del chunk\n",
        "\n",
        "df_train = pd.concat(filtered_chunks, ignore_index=True)\n",
        "df_train = df_train.sample(n=300_000).reset_index(drop=True)\n",
        "del filtered_chunks"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "TaWZc1WdBmJW",
        "outputId": "5bb2773b-258c-4f4a-8eb2-aae4797879e3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.12/dist-packages (5.2.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from gdown) (4.13.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from gdown) (3.20.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.12/dist-packages (from gdown) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from gdown) (4.67.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->gdown) (2.8)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->gdown) (4.15.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (2025.10.5)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (1.7.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1oEX8NEJPY7wPmSJ0n7lO1JUFYyZjFBRv\n",
            "From (redirected): https://drive.google.com/uc?id=1oEX8NEJPY7wPmSJ0n7lO1JUFYyZjFBRv&confirm=t&uuid=47f31935-361c-4d11-86a3-b0348ce90df3\n",
            "To: /content/train.csv\n",
            "100%|██████████| 5.00G/5.00G [01:03<00:00, 78.9MB/s]\n",
            "/tmp/ipython-input-219481652.py:16: DtypeWarning: Columns (5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  for chunk in pd.read_csv(\"train.csv\", chunksize=chunk_size):\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# fill_missing_dates_with_zero_sales"
      ],
      "metadata": {
        "id": "DpYJo4dDKDSj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, we make sure that the `date` column is a proper datetime type and then enforce a complete daily calendar for each `(store_nbr, item_nbr)` combination. For every store–item pair, we reindex the data to a daily frequency and fill missing dates with zeros. We assume that missing dates for a given store–item pair correspond to days with no sales of the corresponding item, which is why it is reasonable to fill them with zero. This gives us a continuous daily time series per product and store, which is important for later time series analysis and forecasting."
      ],
      "metadata": {
        "id": "l5JmtVDMKEAv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_train['date'] = pd.to_datetime(df_train['date'])\n",
        "\n",
        "def fill_calendar(group):\n",
        "\n",
        "    g = group.set_index(\"date\").sort_index()\n",
        "\n",
        "    g[\"store_nbr\"] = group[\"store_nbr\"].iloc[0]\n",
        "    g[\"item_nbr\"]  = group[\"item_nbr\"].iloc[0]\n",
        "\n",
        "    return g.reset_index()\n",
        "\n",
        "df_train = (df_train.groupby([\"store_nbr\", \"item_nbr\"], group_keys=False).apply(fill_calendar))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RDey7zVKM99H",
        "outputId": "73916975-402c-4ef1-c0c2-f405767f3ad1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-953193142.py:17: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  df_train = (df_train.groupby([\"store_nbr\", \"item_nbr\"], group_keys=False).apply(fill_calendar))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# cleaning_onpromotion_and_unit_sales\n"
      ],
      "metadata": {
        "id": "q6lYfng3LLz0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this step, we clean two important columns in `df_train`. First, we handle missing values in the `onpromotion` column by filling all `NaN` entries with `False` and casting the column to a boolean type. This assumes that missing entries indicate that the item was not on promotion on that day. Second, we replace negative values in the `unit_sales` column with `0` using `max(x, 0)`. Negative sales typically represent product returns, and for our demand modelling and forecasting purposes we treat these as days with no effective sales rather than allowing negative demand values.\n"
      ],
      "metadata": {
        "id": "3yndEblzLNgK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_train['onpromotion'] = df_train['onpromotion'].fillna(False).astype(bool)\n",
        "\n",
        "df_train['unit_sales'] = df_train['unit_sales'].apply(lambda x: max(x, 0))"
      ],
      "metadata": {
        "id": "VDU8DdnlCRmb"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# interpolate_missing_oil_prices\n"
      ],
      "metadata": {
        "id": "BwbqPofeLpZ6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this step, we handle missing values in the `dcoilwtico` column of `df_oil`, which represents the daily oil price. We use linear interpolation to fill in the gaps, assuming that prices change smoothly between known observations. The `interpolate(method='linear', limit_direction='both')` call fills missing values by drawing straight lines between existing data points and also propagates interpolation forward and backward at the edges of the series if necessary. This results in a continuous oil price time series without `NaN` values, which is important for using oil prices as a reliable external feature in our later analysis and modelling. In particular, we will later use this cleaned oil price series to investigate whether changes in the oil price have an impact on total sales.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Se0RfHyuLmiR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_oil['dcoilwtico'] = df_oil['dcoilwtico'].interpolate(method='linear', limit_direction='both')"
      ],
      "metadata": {
        "id": "DjwnZYwECnB0"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# filter_df_train_to_top_3_families"
      ],
      "metadata": {
        "id": "6v1CBnEFNrsG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this step, we focus our analysis on the three largest product families in terms of the number of distinct items. We first count how many items belong to each `family` in `df_items` and extract the top three families based on this item count. Using these families, we then collect all corresponding `item_nbr` values and use them to filter `df_train` so that it only contains rows for items belonging to these top-3 families. This reduces the size and complexity of the training data while still keeping a diverse and representative subset of products for our later analysis and modelling."
      ],
      "metadata": {
        "id": "CPJbeDvDM2Np"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "items_per_family = df_items['family'].value_counts().reset_index()\n",
        "items_per_family.columns = ['Family', 'Item Count']\n",
        "top_3_families = items_per_family.head(3)\n",
        "\n",
        "item_ids = df_items[df_items['family'].isin(top_3_families['Family'].unique())]['item_nbr'].unique()\n",
        "\n",
        "df_train = df_train[df_train['item_nbr'].isin(item_ids)]"
      ],
      "metadata": {
        "id": "trHjjy2dDcDm"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# detect_outliers_with_zscore"
      ],
      "metadata": {
        "id": "Z6wm9zSIOF9j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this step, we identify extreme sales values (outliers) within each `(store_nbr, item_nbr)` combination using the Z-score. We first group `df_train` by `store_nbr` and `item_nbr` and, for each group, compute the mean and standard deviation of `unit_sales`. Based on these statistics, we calculate a Z-score for every observation, measuring how many standard deviations each `unit_sales` value is away from the group mean. To avoid division-by-zero issues, we fall back to a standard deviation of `1` if the actual standard deviation is `0`.  \n",
        "\n",
        "After computing the Z-scores, we flag all rows with a Z-score greater than `5` as outliers and store them in the `outliers` DataFrame. Finally, we create a new boolean column `outliers` in `df_train` that marks whether a row’s `id` is part of the detected outliers. This allows us to later analyse, filter, or treat these extreme values separately in our modelling pipeline."
      ],
      "metadata": {
        "id": "y0jMW4ReOBqH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_store_item_zscore(group):\n",
        "    mean_sales = group['unit_sales'].mean()\n",
        "    std_sales = group['unit_sales'].std()\n",
        "    group['z_score'] = (group['unit_sales'] - mean_sales) / (std_sales if std_sales != 0 else 1)\n",
        "    return group\n",
        "\n",
        "df_train_grouped = df_train.groupby(['store_nbr', 'item_nbr']).apply(calculate_store_item_zscore)\n",
        "df_train_grouped.reset_index(drop=True, inplace=True)\n",
        "\n",
        "outliers = df_train_grouped[df_train_grouped['z_score'] > 5]\n",
        "\n",
        "print(f\"Number of outliers detected: {len(outliers)}\")\n",
        "\n",
        "df_train['outliers'] = df_train['id'].isin(outliers['id'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WDnTbQn__8lp",
        "outputId": "a0647aae-a9dd-49a6-a481-cadaefd1fd96"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1760154795.py:12: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  df_train_grouped = df_train.groupby(['store_nbr', 'item_nbr']).apply(calculate_store_item_zscore)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of outliers detected: 120401\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# extract_date_features_for_modelling"
      ],
      "metadata": {
        "id": "xiA_jAhgPBbS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this step, we extract several basic date-related features from the `date` column in `df_train`. Specifically, we create separate columns for the `year`, `month`, and `day`, as well as `day_of_week`, where the day of the week is represented as an integer (Monday = 0, Sunday = 6). These features make calendar information explicit and help our models learn patterns related to seasonality, monthly trends, and weekly effects in the sales data."
      ],
      "metadata": {
        "id": "W5rRT6bsO__K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_train['year'] = df_train['date'].dt.year\n",
        "df_train['month'] = df_train['date'].dt.month\n",
        "df_train['day'] = df_train['date'].dt.day\n",
        "df_train['day_of_week'] = df_train['date'].dt.dayofweek"
      ],
      "metadata": {
        "collapsed": true,
        "id": "w6lPs_0K-ajf"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# add_holiday_information_to_df_train"
      ],
      "metadata": {
        "id": "uofSvc2EQXtx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this step, we enrich `df_train` with information about holidays and special events. First, we convert the `date` column in `df_holiday_events` to a proper datetime type so that it is compatible with the `date` column in `df_train`. We then perform a left merge on `date`, bringing the `type` of each holiday or event into `df_train` for all matching dates. Any missing values in this column are filled with `\"Regular_Day\"`, indicating that there is no special event or holiday on that date. Finally, we rename the `type` column to `holiday` to make its meaning clearer and more explicit in the context of our modelling pipeline. This results in a categorical `holiday` feature that distinguishes between regular days and various types of special days, which can help capture holiday-related effects on sales."
      ],
      "metadata": {
        "id": "uYlB3T1dQWN1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_holiday_events['date'] = pd.to_datetime(df_holiday_events['date'])\n",
        "df_train = pd.merge(df_train, df_holiday_events[['date', 'type']], on='date', how='left')\n",
        "df_train['type'] = df_train['type'].fillna('Regular_Day')\n",
        "df_train.rename(columns={'type': 'holiday'}, inplace=True)"
      ],
      "metadata": {
        "id": "wwNkVPGHHzF0"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# add_perishable_flag_to_df_train"
      ],
      "metadata": {
        "id": "mN-0s7k2Qsee"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this step, we enrich `df_train` with additional item-level information from `df_items`. We perform a left merge on the `item_nbr` column so that each row in `df_train` receives the corresponding item attributes (such as family or perishability) from `df_items`. After the merge, we cast the `perishable` column to a boolean type, making it explicit whether an item is perishable (`True`) or non-perishable (`False`). This feature is important because perishable items often exhibit different demand patterns and lifecycle behaviour compared to non-perishable products, which can influence our modelling and forecasting results."
      ],
      "metadata": {
        "id": "JPyrdVw1QrFm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_train = pd.merge(df_train, df_items, on='item_nbr', how='left')\n",
        "df_train['perishable'] = df_train['perishable'].astype(bool)"
      ],
      "metadata": {
        "id": "zjLyISiQL95x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# add_7day_rolling_average_of_unit_sales"
      ],
      "metadata": {
        "id": "FpBBgbXwRjsQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this step, we create a 7-day rolling average of `unit_sales` for each `(item_nbr, store_nbr)` combination. First, we sort `df_train` by `item_nbr`, `store_nbr`, and `date` to ensure that each time series is in correct chronological order. We then group the data by `item_nbr` and `store_nbr` and apply a rolling window of 7 days on the `unit_sales` column, using `min_periods=1` so that the first few days still receive an average based on the available history. The result is stored in a new feature called `unit_sales_7d_avg`, which captures short-term demand trends and smooths out daily fluctuations. This smoothed signal can be very helpful for models that benefit from recent demand dynamics without being overly sensitive to single-day spikes or drops."
      ],
      "metadata": {
        "id": "Gntvcw3eRVAC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_train = df_train.sort_values([\"item_nbr\", \"store_nbr\", \"date\"]).reset_index(drop=True)\n",
        "df_train[\"unit_sales_7d_avg\"] = (\n",
        "    df_train\n",
        "    .groupby([\"item_nbr\", \"store_nbr\"])[\"unit_sales\"]\n",
        "    .transform(lambda s: s.rolling(window=7, min_periods=1).mean())\n",
        ")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "OyKmgORq9NiS"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 617
        },
        "id": "tDLy0_NYIikp",
        "outputId": "7ebf24e7-71f0-4330-9900-8e3fab87af8a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "               date         id  store_nbr  item_nbr  unit_sales  onpromotion  \\\n",
              "0        2013-02-05    1402408         24     96995         1.0        False   \n",
              "1        2013-02-06          0         24     96995         0.0        False   \n",
              "2        2013-02-07          0         24     96995         0.0        False   \n",
              "3        2013-02-08          0         24     96995         0.0        False   \n",
              "4        2013-02-09          0         24     96995         0.0        False   \n",
              "...             ...        ...        ...       ...         ...          ...   \n",
              "17843942 2017-08-12  125134313         29   2113343         1.0        False   \n",
              "17843943 2017-07-21  122819909         29   2113914        12.0         True   \n",
              "17843944 2017-08-14  125354524         36   2116416         1.0        False   \n",
              "17843945 2017-08-10  124924419         27   2122188         3.0        False   \n",
              "17843946 2017-08-13  125239755         29   2123410         2.0        False   \n",
              "\n",
              "          outliers  year  month  day  day_of_week      holiday     family  \\\n",
              "0             True  2013      2    5            1  Regular_Day  GROCERY I   \n",
              "1            False  2013      2    6            2  Regular_Day  GROCERY I   \n",
              "2            False  2013      2    7            3  Regular_Day  GROCERY I   \n",
              "3            False  2013      2    8            4  Regular_Day  GROCERY I   \n",
              "4            False  2013      2    9            5  Regular_Day  GROCERY I   \n",
              "...            ...   ...    ...  ...          ...          ...        ...   \n",
              "17843942     False  2017      8   12            5  Regular_Day  BEVERAGES   \n",
              "17843943     False  2017      7   21            4  Regular_Day   CLEANING   \n",
              "17843944     False  2017      8   14            0  Regular_Day  GROCERY I   \n",
              "17843945     False  2017      8   10            3      Holiday  GROCERY I   \n",
              "17843946     False  2017      8   13            6  Regular_Day  GROCERY I   \n",
              "\n",
              "          class  perishable  unit_sales_7d_avg  \n",
              "0          1093       False           1.000000  \n",
              "1          1093       False           0.500000  \n",
              "2          1093       False           0.333333  \n",
              "3          1093       False           0.250000  \n",
              "4          1093       False           0.200000  \n",
              "...         ...         ...                ...  \n",
              "17843942   1114       False           1.000000  \n",
              "17843943   3040       False          12.000000  \n",
              "17843944   1060       False           1.000000  \n",
              "17843945   1084       False           3.000000  \n",
              "17843946   1012       False           2.000000  \n",
              "\n",
              "[17843947 rows x 16 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ce591721-4af4-4c08-aea2-107761ad2a2d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>id</th>\n",
              "      <th>store_nbr</th>\n",
              "      <th>item_nbr</th>\n",
              "      <th>unit_sales</th>\n",
              "      <th>onpromotion</th>\n",
              "      <th>outliers</th>\n",
              "      <th>year</th>\n",
              "      <th>month</th>\n",
              "      <th>day</th>\n",
              "      <th>day_of_week</th>\n",
              "      <th>holiday</th>\n",
              "      <th>family</th>\n",
              "      <th>class</th>\n",
              "      <th>perishable</th>\n",
              "      <th>unit_sales_7d_avg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2013-02-05</td>\n",
              "      <td>1402408</td>\n",
              "      <td>24</td>\n",
              "      <td>96995</td>\n",
              "      <td>1.0</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>2013</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>Regular_Day</td>\n",
              "      <td>GROCERY I</td>\n",
              "      <td>1093</td>\n",
              "      <td>False</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2013-02-06</td>\n",
              "      <td>0</td>\n",
              "      <td>24</td>\n",
              "      <td>96995</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>2013</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>Regular_Day</td>\n",
              "      <td>GROCERY I</td>\n",
              "      <td>1093</td>\n",
              "      <td>False</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2013-02-07</td>\n",
              "      <td>0</td>\n",
              "      <td>24</td>\n",
              "      <td>96995</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>2013</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "      <td>Regular_Day</td>\n",
              "      <td>GROCERY I</td>\n",
              "      <td>1093</td>\n",
              "      <td>False</td>\n",
              "      <td>0.333333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2013-02-08</td>\n",
              "      <td>0</td>\n",
              "      <td>24</td>\n",
              "      <td>96995</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>2013</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "      <td>4</td>\n",
              "      <td>Regular_Day</td>\n",
              "      <td>GROCERY I</td>\n",
              "      <td>1093</td>\n",
              "      <td>False</td>\n",
              "      <td>0.250000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2013-02-09</td>\n",
              "      <td>0</td>\n",
              "      <td>24</td>\n",
              "      <td>96995</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>2013</td>\n",
              "      <td>2</td>\n",
              "      <td>9</td>\n",
              "      <td>5</td>\n",
              "      <td>Regular_Day</td>\n",
              "      <td>GROCERY I</td>\n",
              "      <td>1093</td>\n",
              "      <td>False</td>\n",
              "      <td>0.200000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17843942</th>\n",
              "      <td>2017-08-12</td>\n",
              "      <td>125134313</td>\n",
              "      <td>29</td>\n",
              "      <td>2113343</td>\n",
              "      <td>1.0</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>2017</td>\n",
              "      <td>8</td>\n",
              "      <td>12</td>\n",
              "      <td>5</td>\n",
              "      <td>Regular_Day</td>\n",
              "      <td>BEVERAGES</td>\n",
              "      <td>1114</td>\n",
              "      <td>False</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17843943</th>\n",
              "      <td>2017-07-21</td>\n",
              "      <td>122819909</td>\n",
              "      <td>29</td>\n",
              "      <td>2113914</td>\n",
              "      <td>12.0</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>2017</td>\n",
              "      <td>7</td>\n",
              "      <td>21</td>\n",
              "      <td>4</td>\n",
              "      <td>Regular_Day</td>\n",
              "      <td>CLEANING</td>\n",
              "      <td>3040</td>\n",
              "      <td>False</td>\n",
              "      <td>12.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17843944</th>\n",
              "      <td>2017-08-14</td>\n",
              "      <td>125354524</td>\n",
              "      <td>36</td>\n",
              "      <td>2116416</td>\n",
              "      <td>1.0</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>2017</td>\n",
              "      <td>8</td>\n",
              "      <td>14</td>\n",
              "      <td>0</td>\n",
              "      <td>Regular_Day</td>\n",
              "      <td>GROCERY I</td>\n",
              "      <td>1060</td>\n",
              "      <td>False</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17843945</th>\n",
              "      <td>2017-08-10</td>\n",
              "      <td>124924419</td>\n",
              "      <td>27</td>\n",
              "      <td>2122188</td>\n",
              "      <td>3.0</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>2017</td>\n",
              "      <td>8</td>\n",
              "      <td>10</td>\n",
              "      <td>3</td>\n",
              "      <td>Holiday</td>\n",
              "      <td>GROCERY I</td>\n",
              "      <td>1084</td>\n",
              "      <td>False</td>\n",
              "      <td>3.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17843946</th>\n",
              "      <td>2017-08-13</td>\n",
              "      <td>125239755</td>\n",
              "      <td>29</td>\n",
              "      <td>2123410</td>\n",
              "      <td>2.0</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>2017</td>\n",
              "      <td>8</td>\n",
              "      <td>13</td>\n",
              "      <td>6</td>\n",
              "      <td>Regular_Day</td>\n",
              "      <td>GROCERY I</td>\n",
              "      <td>1012</td>\n",
              "      <td>False</td>\n",
              "      <td>2.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>17843947 rows × 16 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ce591721-4af4-4c08-aea2-107761ad2a2d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ce591721-4af4-4c08-aea2-107761ad2a2d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ce591721-4af4-4c08-aea2-107761ad2a2d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-76505fd5-18e5-4e26-b875-cca0601d589f\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-76505fd5-18e5-4e26-b875-cca0601d589f')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-76505fd5-18e5-4e26-b875-cca0601d589f button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_b8ac56e4-25e3-4f56-847d-6c90e78f8762\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_train')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_b8ac56e4-25e3-4f56-847d-6c90e78f8762 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_train');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_train"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# save_clean_df_train_to_google_drive"
      ],
      "metadata": {
        "id": "CmxVW18AR2U4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this step, we save our cleaned `df_train` DataFrame to Google Drive so that we can easily reuse it later without having to repeat all preprocessing steps. First, we mount Google Drive in the Colab environment using `drive.mount('/content/drive')`, which requires a one-time authorization click. Next, we define a `save_path` inside our Drive where the file should be stored. Finally, we use `df_train.to_pickle(save_path)` to save the DataFrame in pickle format, which preserves data types and is efficient to load back into memory. This allows us to quickly reload the preprocessed dataset in future notebooks or sessions by simply reading the pickle file from the same path."
      ],
      "metadata": {
        "id": "luGatvoBR0fO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "save_path = \"/content/drive/MyDrive/time_series_course/df_train_clean.pkl\" # example of path\n",
        "\n",
        "df_train.to_pickle(save_path)\n",
        "print(f\"Saved to: {save_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q6YjNxlPGA86",
        "outputId": "c5c7ef44-bee8-4840-d863-65c4a343c32e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Saved to: /content/drive/MyDrive/time_series_course/df_train_clean.pkl\n"
          ]
        }
      ]
    }
  ]
}